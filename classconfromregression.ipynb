{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe2a8f36",
   "metadata": {},
   "source": [
    "Create a class for the inductive cross conformal predictor for the case of regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fddd3f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class cross_confrom_regress():\n",
    "    \n",
    "    \n",
    "    def __init__(self, X_train, y_train, model):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.model = model\n",
    "        self.fitted_model = model.fit(X_train, y_train)\n",
    "        \n",
    "        \n",
    "    def get_prediction_interval(self, e, get_test_error = False, X_test = None, y_test = None):\n",
    "        \n",
    "        \"\"\"\n",
    "        This function gives the prediction interval for a particular error rate e. The validity of that particular interval\n",
    "        can be checked by using the the interval test error rate. To do this set get_test_error = True.\n",
    "        \"\"\"\n",
    "        X_train = self.X_train # get object attributes \n",
    "        y_train = self.y_train\n",
    "        model = self.model\n",
    "        \n",
    "        kf = KFold(shuffle = True, random_state = 211)\n",
    "        all_non_conform = np.array([]) # empty array to store all non conformity scores \n",
    "\n",
    "        for rest_indx, fold_indx in kf.split(X_train):\n",
    "            X_rest, X_fold = X_train[rest_indx], X_train[fold_indx] # fold is used as calibration set\n",
    "            y_rest, y_fold = y_train[rest_indx], y_train[fold_indx]\n",
    "            current_model = copy.deepcopy(model) # make a copy to prevent variable inheritance\n",
    "            current_model.fit(X_rest, y_rest) # fit the current model with the data not in the current fold\n",
    "        \n",
    "            y_hat = current_model.predict(X_fold) # find the predictions for every sample \n",
    "            current_nonconform = np.absolute(y_fold - y_hat)  # calculate non conformity scores \n",
    "            all_non_conform = np.append(all_non_conform, current_nonconform) #append current non conform scores to all\n",
    "    \n",
    "        non_conform = np.sort(all_non_conform) # sort the non confromity scores in accending order \n",
    "\n",
    "        k = int((1 - e) * (non_conform.size + 1)) # calculate the non-confimity index for given e \n",
    "        c = non_conform[k] # obtain the non-conformity score which satisfies e (-1 as python indexs from o)\n",
    "        \n",
    "        prediction_interval = c # set c as the prediction interval\n",
    "        \n",
    "        if get_test_error == True:\n",
    "            \n",
    "            fitted_model = self.fitted_model\n",
    "            current_model = copy.deepcopy(fitted_model) # get a copy of the fitted model\n",
    "            y_hat = current_model.predict(X_test) # get predicted y values for the test set \n",
    "            error = np.zeros(y_test.size) # create an empty \n",
    "    \n",
    "            for i in range(y_test.size):\n",
    "                current_prediction = y_hat[i] # get the current y_hat\n",
    "                lower_bound = current_prediction - c # get the upper and lower bounds of the curent y hat\n",
    "                upper_bound = current_prediction + c\n",
    "        \n",
    "                if y_test[i] < lower_bound or y_test[i] > upper_bound: # if out of prediction interval \n",
    "                    error[i] = 1 # set error to 1 if there an error on current y_hat\n",
    "    \n",
    "                error_rate = np.mean(error) # get the mean of the error rates \n",
    "        \n",
    "        else:\n",
    "            error_rate = None\n",
    "            \n",
    "        return prediction_interval, error_rate\n",
    "    \n",
    "    \n",
    "        def get_calibration_curve(self, X_test, y_test, get_inter = False):\n",
    "            \n",
    "            \"\"\"\n",
    "            This function produces a calibration curve to check the validitiy of the confornal predictor. Also, if \n",
    "            get_inter = True, then the intervals for error rates between 0.01 and 1 with step 0.01 may be obtained. \n",
    "            \"\"\"\n",
    "            \n",
    "            error_rates = np.arange(0.01, 1, 0.01) # get error rates in range 0.01 to 1 with step 0.01\n",
    "            test_error_rates = np.zeros(error_rates.size)\n",
    "            all_inter = np.zeros(error_rates.size)\n",
    "            \n",
    "            for i in range(error_rate.size):\n",
    "                # use previous function to get test error rate for current error rate in loop\n",
    "                predict_inter, t_error_rate = get_prediction_interval(error_rate[i], True, X_test, y_test)\n",
    "                test_error_rates[i] = t_error_rate\n",
    "                all_inter[i] = predict_inter\n",
    "            \n",
    "            plt.plot(error_rates, test_error_rates) # plot the calibration curve \n",
    "            plt.xlabel('error rate')\n",
    "            plt.ylabel('test error rate')\n",
    "            plt.title('Calibration curve')\n",
    "            plt.show()\n",
    "            \n",
    "            if get_inter == False:\n",
    "                all_inter = None\n",
    "            \n",
    "            return all_inter"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
